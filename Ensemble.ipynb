{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tq5KQGn9nbaF",
    "outputId": "123d5b63-ef1c-44f9-cf33-1eb11ecbfb04"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.activations import relu\n",
    "from keras.activations import linear\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers as Layers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential#Import from keras_preprocessing not from keras.preprocessingfrom keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "# import seaborn as sn\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nys_bv3QKv_O"
   },
   "source": [
    "Loading Data:\n",
    "The dataset has been splited into 20% for validation and 80% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNf5aYI3nvt4",
    "outputId": "d7894284-7505-4e24-a621-f71698ffa588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24750 files belonging to 45 classes.\n",
      "Using 19800 files for training.\n",
      "Found 6750 files belonging to 45 classes.\n",
      "Using 1350 files for validation.\n",
      "['airplane', 'airport', 'baseball_diamond', 'basketball_court', 'beach', 'bridge', 'chaparral', 'church', 'circular_farmland', 'cloud', 'commercial_area', 'dense_residential', 'desert', 'forest', 'freeway', 'golf_course', 'ground_track_field', 'harbor', 'industrial_area', 'intersection', 'island', 'lake', 'meadow', 'medium_residential', 'mobile_home_park', 'mountain', 'overpass', 'palace', 'parking_lot', 'railway', 'railway_station', 'rectangular_farmland', 'river', 'roundabout', 'runway', 'sea_ice', 'ship', 'snowberg', 'sparse_residential', 'stadium', 'storage_tank', 'tennis_court', 'terrace', 'thermal_power_station', 'wetland']\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "train_data_path = 'E:/OldDrive/Yasin/Fall2021/Neural_Network/Kimia/HW3/NWPU-RESISC45/train_ds'\n",
    "test_data_path = 'E:/OldDrive/Yasin/Fall2021/Neural_Network/Kimia/HW3/NWPU-RESISC45/test_ds'\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_data_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_data_path,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjM8DAI1K-_o"
   },
   "source": [
    "**Run 1:**\n",
    "The relu activation function has been used in Con2D layers and MaxPooling layers. \n",
    "The optimizer in this run is Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 11: Ensemble Training with Different Nets (Tried to run Resnet 3times each one 20 epochs and then combine three models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(Model):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(ResBlock, self).__init__(name='ResBlock')\n",
    "        self.flag = (stride != 1)\n",
    "        self.conv1 = Conv2D(channels, 3, stride, padding='same')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.conv2 = Conv2D(channels, 3, padding='same')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.relu = ReLU()\n",
    "        if self.flag:\n",
    "            self.bn3 = BatchNormalization()\n",
    "            self.conv3 = Conv2D(channels, 1, stride)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.bn2(x1)\n",
    "        if self.flag:\n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "        x1 = Layers.add([x, x1])\n",
    "        x1 = self.relu(x1)\n",
    "        return x1\n",
    "\n",
    "\n",
    "class ResNet34(Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet34, self).__init__(name='ResNet34')\n",
    "        self.conv1 = Conv2D(64, 7, 2, padding='same')\n",
    "        self.bn = BatchNormalization()\n",
    "        self.relu = ReLU()\n",
    "        self.mp1 = MaxPooling2D(3, 2)\n",
    "\n",
    "        self.conv2_1 = ResBlock(64)\n",
    "        self.conv2_2 = ResBlock(64)\n",
    "        self.conv2_3 = ResBlock(64)\n",
    "\n",
    "        self.conv3_1 = ResBlock(128, 2)\n",
    "        self.conv3_2 = ResBlock(128)\n",
    "        self.conv3_3 = ResBlock(128)\n",
    "        self.conv3_4 = ResBlock(128)\n",
    "\n",
    "        self.conv4_1 = ResBlock(256, 2)\n",
    "        self.conv4_2 = ResBlock(256)\n",
    "        self.conv4_3 = ResBlock(256)\n",
    "        self.conv4_4 = ResBlock(256)\n",
    "        self.conv4_5 = ResBlock(256)\n",
    "        self.conv4_6 = ResBlock(256)\n",
    "\n",
    "        self.conv5_1 = ResBlock(512, 2)\n",
    "        self.conv5_2 = ResBlock(512)\n",
    "        self.conv5_3 = ResBlock(512)\n",
    "\n",
    "        self.pool = GlobalAveragePooling2D()\n",
    "        self.fc1 = Dense(512, activation='relu')\n",
    "        self.dp1 = Dropout(0.5)\n",
    "        self.fc2 = Dense(512, activation='relu')\n",
    "        self.dp2 = Dropout(0.5)\n",
    "        self.fc3 = Dense(45)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp1(x)\n",
    "\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.conv2_3(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.conv3_4(x)\n",
    "\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.conv4_4(x)\n",
    "        x = self.conv4_5(x)\n",
    "        x = self.conv4_6(x)\n",
    "\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.conv5_3(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34()\n",
    "model.build(input_shape=(1, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 0 is being trained...\n",
      "Epoch 1/20\n",
      "619/619 [==============================] - 45s 69ms/step - loss: 1.7586 - accuracy: 0.4832 - val_loss: 1.4881 - val_accuracy: 0.5504\n",
      "Epoch 2/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 1.6448 - accuracy: 0.5153 - val_loss: 2.0347 - val_accuracy: 0.5015\n",
      "Epoch 3/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 1.5481 - accuracy: 0.5379 - val_loss: 15.1806 - val_accuracy: 0.2637\n",
      "Epoch 4/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 1.4534 - accuracy: 0.5667 - val_loss: 1.3129 - val_accuracy: 0.6259\n",
      "Epoch 5/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 1.3906 - accuracy: 0.5886 - val_loss: 2.2244 - val_accuracy: 0.4119\n",
      "Epoch 6/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 1.2932 - accuracy: 0.6135 - val_loss: 1.1299 - val_accuracy: 0.6615\n",
      "Epoch 7/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 1.1626 - accuracy: 0.6485 - val_loss: 1.0561 - val_accuracy: 0.6830\n",
      "Epoch 8/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 1.0750 - accuracy: 0.6707 - val_loss: 3.9160 - val_accuracy: 0.6652\n",
      "Epoch 9/20\n",
      "619/619 [==============================] - 42s 69ms/step - loss: 0.9507 - accuracy: 0.7128 - val_loss: 13.0957 - val_accuracy: 0.6504\n",
      "Epoch 10/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 0.9482 - accuracy: 0.7154 - val_loss: 3.4164 - val_accuracy: 0.3652\n",
      "Epoch 11/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 0.9025 - accuracy: 0.7290 - val_loss: 2.2234 - val_accuracy: 0.5830\n",
      "Epoch 12/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.8345 - accuracy: 0.7464 - val_loss: 1.4610 - val_accuracy: 0.5926\n",
      "Epoch 13/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.6994 - accuracy: 0.7846 - val_loss: 0.9526 - val_accuracy: 0.7430\n",
      "Epoch 14/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.6384 - accuracy: 0.8037 - val_loss: 1.9586 - val_accuracy: 0.7356\n",
      "Epoch 15/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.6546 - accuracy: 0.7996 - val_loss: 1.3094 - val_accuracy: 0.6881\n",
      "Epoch 16/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 0.6113 - accuracy: 0.8132 - val_loss: 52.7175 - val_accuracy: 0.3681\n",
      "Epoch 17/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.4698 - accuracy: 0.8546 - val_loss: 0.9347 - val_accuracy: 0.7659\n",
      "Epoch 18/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.5210 - accuracy: 0.8454 - val_loss: 2.3046 - val_accuracy: 0.5296\n",
      "Epoch 19/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 0.4352 - accuracy: 0.8669 - val_loss: 1.4465 - val_accuracy: 0.7622\n",
      "Epoch 20/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.3514 - accuracy: 0.8923 - val_loss: 1.0535 - val_accuracy: 0.7659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_110_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses, re_lu_51_layer_call_fn, re_lu_51_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 290). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_0.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_0.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 1 is being trained...\n",
      "Epoch 1/20\n",
      "619/619 [==============================] - 44s 69ms/step - loss: 0.4248 - accuracy: 0.8751 - val_loss: 8.3457 - val_accuracy: 0.7281\n",
      "Epoch 2/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.3212 - accuracy: 0.9023 - val_loss: 1.1097 - val_accuracy: 0.7681\n",
      "Epoch 3/20\n",
      "619/619 [==============================] - 43s 70ms/step - loss: 0.3383 - accuracy: 0.9010 - val_loss: 2.7111 - val_accuracy: 0.4896\n",
      "Epoch 4/20\n",
      "619/619 [==============================] - 43s 70ms/step - loss: 0.3589 - accuracy: 0.8970 - val_loss: 1.0648 - val_accuracy: 0.7748\n",
      "Epoch 5/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.2325 - accuracy: 0.9288 - val_loss: 2.5703 - val_accuracy: 0.7541\n",
      "Epoch 6/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.2886 - accuracy: 0.9146 - val_loss: 1.0838 - val_accuracy: 0.7659\n",
      "Epoch 7/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.4102 - accuracy: 0.8909 - val_loss: 1242.2654 - val_accuracy: 0.1015\n",
      "Epoch 8/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.4224 - accuracy: 0.8790 - val_loss: 1.0095 - val_accuracy: 0.7822\n",
      "Epoch 9/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.2831 - accuracy: 0.9208 - val_loss: 1.5498 - val_accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.2733 - accuracy: 0.9253 - val_loss: 1.1143 - val_accuracy: 0.7881\n",
      "Epoch 11/20\n",
      "619/619 [==============================] - 43s 70ms/step - loss: 0.2527 - accuracy: 0.9266 - val_loss: 1.3480 - val_accuracy: 0.7407\n",
      "Epoch 12/20\n",
      "619/619 [==============================] - 43s 69ms/step - loss: 0.2335 - accuracy: 0.9355 - val_loss: 1.1290 - val_accuracy: 0.7837\n",
      "Epoch 13/20\n",
      "619/619 [==============================] - 43s 70ms/step - loss: 0.2099 - accuracy: 0.9424 - val_loss: 1.8510 - val_accuracy: 0.6941\n",
      "Epoch 14/20\n",
      "619/619 [==============================] - 42s 68ms/step - loss: 0.3510 - accuracy: 0.9025 - val_loss: 72.8603 - val_accuracy: 0.2007\n",
      "Epoch 15/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2776 - accuracy: 0.9240 - val_loss: 1.2037 - val_accuracy: 0.7830\n",
      "Epoch 16/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2288 - accuracy: 0.9360 - val_loss: 1.3943 - val_accuracy: 0.7519\n",
      "Epoch 17/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.2905 - accuracy: 0.9207 - val_loss: 2.1337 - val_accuracy: 0.6185\n",
      "Epoch 18/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.3465 - accuracy: 0.9084 - val_loss: 4.8585 - val_accuracy: 0.3067\n",
      "Epoch 19/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.2193 - accuracy: 0.9414 - val_loss: 1.3655 - val_accuracy: 0.7541\n",
      "Epoch 20/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1910 - accuracy: 0.9468 - val_loss: 1.2468 - val_accuracy: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_110_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses, re_lu_51_layer_call_fn, re_lu_51_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 290). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_1.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_1.model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net 2 is being trained...\n",
      "Epoch 1/20\n",
      "619/619 [==============================] - 43s 67ms/step - loss: 0.2184 - accuracy: 0.9402 - val_loss: 1.2160 - val_accuracy: 0.7719\n",
      "Epoch 2/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2991 - accuracy: 0.9174 - val_loss: 1.2014 - val_accuracy: 0.7474\n",
      "Epoch 3/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2953 - accuracy: 0.9197 - val_loss: 1.1241 - val_accuracy: 0.7793\n",
      "Epoch 4/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1907 - accuracy: 0.9463 - val_loss: 1.3184 - val_accuracy: 0.7541\n",
      "Epoch 5/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.1629 - accuracy: 0.9527 - val_loss: 1.3163 - val_accuracy: 0.7756\n",
      "Epoch 6/20\n",
      "619/619 [==============================] - 42s 67ms/step - loss: 0.1622 - accuracy: 0.9533 - val_loss: 1.3329 - val_accuracy: 0.7726\n",
      "Epoch 7/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1643 - accuracy: 0.9538 - val_loss: 1.3426 - val_accuracy: 0.7652\n",
      "Epoch 8/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1365 - accuracy: 0.9576 - val_loss: 1.5513 - val_accuracy: 0.7556\n",
      "Epoch 9/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2698 - accuracy: 0.9237 - val_loss: 1.4454 - val_accuracy: 0.7259\n",
      "Epoch 10/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.3047 - accuracy: 0.9177 - val_loss: 1.5642 - val_accuracy: 0.7015\n",
      "Epoch 11/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2493 - accuracy: 0.9354 - val_loss: 2.5279 - val_accuracy: 0.4978\n",
      "Epoch 12/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2278 - accuracy: 0.9411 - val_loss: 21.6725 - val_accuracy: 0.7704\n",
      "Epoch 13/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2104 - accuracy: 0.9467 - val_loss: 3.8591 - val_accuracy: 0.3533\n",
      "Epoch 14/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.3067 - accuracy: 0.9191 - val_loss: 1.3332 - val_accuracy: 0.7526\n",
      "Epoch 15/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2707 - accuracy: 0.9284 - val_loss: 1.7722 - val_accuracy: 0.7052\n",
      "Epoch 16/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2277 - accuracy: 0.9403 - val_loss: 1.5315 - val_accuracy: 0.7333\n",
      "Epoch 17/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2068 - accuracy: 0.9448 - val_loss: 1.7575 - val_accuracy: 0.7156\n",
      "Epoch 18/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.2089 - accuracy: 0.9454 - val_loss: 1.3793 - val_accuracy: 0.7748\n",
      "Epoch 19/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1599 - accuracy: 0.9581 - val_loss: 1.3037 - val_accuracy: 0.7970\n",
      "Epoch 20/20\n",
      "619/619 [==============================] - 41s 67ms/step - loss: 0.1339 - accuracy: 0.9664 - val_loss: 1.4000 - val_accuracy: 0.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_110_layer_call_fn, conv2d_110_layer_call_and_return_conditional_losses, re_lu_51_layer_call_fn, re_lu_51_layer_call_and_return_conditional_losses, dense_9_layer_call_fn while saving (showing 5 of 290). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_2.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models1\\model_2.model\\assets\n"
     ]
    }
   ],
   "source": [
    "numberOfModels = 3\n",
    "for i in range(numberOfModels):\n",
    "    print('Net', i, 'is being trained...')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    epochs=20\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=epochs,\n",
    "      batch_size=64\n",
    "    )\n",
    "    # save the model\n",
    "    p = ['models1', 'model_{}.model'.format(i)]\n",
    "    model.save(os.path.sep.join(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 1/3\n",
      "Loading model 2/3\n",
      "Loading model 3/3\n",
      "Evaluating ensemble...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88        36\n",
      "           1       0.58      0.61      0.60        23\n",
      "           2       0.78      0.86      0.82        29\n",
      "           3       0.79      0.71      0.75        31\n",
      "           4       0.77      0.92      0.84        26\n",
      "           5       0.83      0.83      0.83        30\n",
      "           6       0.90      1.00      0.95        19\n",
      "           7       0.75      0.56      0.64        27\n",
      "           8       0.86      0.89      0.88        28\n",
      "           9       0.94      1.00      0.97        29\n",
      "          10       0.71      0.74      0.72        34\n",
      "          11       0.81      0.91      0.86        33\n",
      "          12       0.97      0.93      0.95        40\n",
      "          13       0.97      0.91      0.94        33\n",
      "          14       0.73      0.73      0.73        33\n",
      "          15       0.75      0.96      0.84        28\n",
      "          16       0.89      0.91      0.90        34\n",
      "          17       0.97      1.00      0.99        33\n",
      "          18       0.70      0.64      0.67        25\n",
      "          19       0.83      0.86      0.84        28\n",
      "          20       1.00      1.00      1.00        34\n",
      "          21       0.89      0.96      0.93        26\n",
      "          22       0.92      0.94      0.93        35\n",
      "          23       0.80      0.75      0.77        32\n",
      "          24       0.89      0.83      0.86        29\n",
      "          25       0.85      0.85      0.85        33\n",
      "          26       0.93      0.78      0.85        32\n",
      "          27       0.78      0.60      0.68        35\n",
      "          28       0.90      0.93      0.91        28\n",
      "          29       0.83      0.74      0.78        27\n",
      "          30       0.65      0.67      0.66        33\n",
      "          31       0.69      0.75      0.72        24\n",
      "          32       0.64      0.67      0.65        27\n",
      "          33       0.88      0.75      0.81        28\n",
      "          34       0.84      0.90      0.87        29\n",
      "          35       0.97      0.97      0.97        34\n",
      "          36       0.76      0.85      0.80        26\n",
      "          37       0.85      0.88      0.86        25\n",
      "          38       0.88      0.95      0.91        22\n",
      "          39       1.00      0.97      0.98        30\n",
      "          40       0.79      0.81      0.80        32\n",
      "          41       0.72      0.72      0.72        29\n",
      "          42       0.91      0.86      0.88        35\n",
      "          43       0.82      0.85      0.84        27\n",
      "          44       0.95      0.92      0.94        39\n",
      "\n",
      "    accuracy                           0.84      1350\n",
      "   macro avg       0.84      0.84      0.83      1350\n",
      "weighted avg       0.84      0.84      0.84      1350\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# construct the path used to collect the models then initialize the\n",
    "# models list\n",
    "modelPaths = os.path.sep.join(['models1', '*.model'])\n",
    "modelPaths = list(glob.glob(modelPaths))\n",
    "models = []\n",
    "\n",
    "# loop over the model paths, loading the model, and adding it to\n",
    "# the list of models\n",
    "for (i, modelPath) in enumerate(modelPaths):\n",
    "    print('Loading model {}/{}'.format(i + 1, len(modelPaths)))\n",
    "    models.append(load_model(modelPath))\n",
    "\n",
    "# initialize the list of predictions\n",
    "print('Evaluating ensemble...')\n",
    "predictions = []\n",
    "\n",
    "predictedY = model.predict(val_ds)\n",
    "predictedY = np.argmax(predictedY, axis=1)\n",
    "testX = np.concatenate([x for x, y in val_ds], axis=0)\n",
    "testY = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "# loop over the models\n",
    "for model in models:\n",
    "    # use the current model to make predictions on the testing data,\n",
    "    # then store these predictions in the aggregate predictions list\n",
    "    predictions.append(model.predict(testX, batch_size=64))\n",
    "\n",
    "# average the probabilities across all model predictions\n",
    "predictions = np.average(predictions, axis=0)\n",
    "\n",
    "#show a classification report\n",
    "print(classification_report(testY,\n",
    "                            predictions.argmax(axis=1)))\n",
    "\n",
    "heatmap(confusion_matrix(testY, predictions.argmax(axis=1)))\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run 12: Ensemble Training with Different Nets (Tried to run Resnet and Alexnet 2times each one 20 epochs and then combine two models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 256, 256, 96)      34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 256, 256, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 128, 128, 256)     614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 66, 66, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 66, 66, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 66, 66, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 66, 66, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 33, 33, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 35, 35, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 35, 35, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 35, 35, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 35, 35, 1024)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 37, 37, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 37, 37, 1024)      9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 37, 37, 1024)      4096      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 37, 37, 1024)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 18, 18, 1024)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 331776)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3072)              1019218944\n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              12587008  \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 45)                184365    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 45)                180       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 45)                0         \n",
      "=================================================================\n",
      "Total params: 1,048,018,401\n",
      "Trainable params: 1,047,998,151\n",
      "Non-trainable params: 20,250\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def AlexNet(img_shape=(256, 256, 3), n_classes=45, l2_reg=0.,\n",
    "\tweights=None):\n",
    "\n",
    "\t# Initialize model\n",
    "\talexnet = Sequential()\n",
    "\n",
    "\t# Layer 1\n",
    "\talexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
    "\t\tpadding='same', kernel_regularizer=l2(l2_reg)))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 2\n",
    "\talexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 3\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 4\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\n",
    "\t# Layer 5\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 6\n",
    "\talexnet.add(Flatten())\n",
    "\talexnet.add(Dense(3072))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 7\n",
    "\talexnet.add(Dense(4096))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(LeakyReLU(alpha=0.1))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 8\n",
    "\talexnet.add(Dense(n_classes))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\n",
    "\tif weights is not None:\n",
    "\t\talexnet.load_weights(weights)\n",
    "\n",
    "\treturn alexnet\n",
    "\n",
    "model = AlexNet()\n",
    "model.build(input_shape=(256, 256, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet 0 is being trained...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ResNet34' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-27d1d1a2576d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumberOfModels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ResNet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is being trained...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     model.compile(optimizer='adam',\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ResNet34' is not defined"
     ]
    }
   ],
   "source": [
    "numberOfModels = 1\n",
    "for i in range(numberOfModels):\n",
    "    print('ResNet', i, 'is being trained...')\n",
    "    model = ResNet34()\n",
    "    model.build(input_shape=(1, 256, 256, 3))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    epochs=20\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=epochs,\n",
    "      batch_size=64\n",
    "    )\n",
    "    # save the model\n",
    "    p = ['models2', 'model_{}.model'.format(i)]\n",
    "    model.save(os.path.sep.join(p))\n",
    "\n",
    "    \n",
    "for i in range(numberOfModels, 2*numberOfModels):\n",
    "    print('AlexNet', i - numberOfModels + 1, 'is being trained...')\n",
    "    model = AlexNet()\n",
    "    model.build(input_shape=(256, 256, 3))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    epochs=20\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=epochs,\n",
    "      batch_size=64\n",
    "    )\n",
    "    # save the model\n",
    "    p = ['models2', 'model_{}.model'.format(i)]\n",
    "    model.save(os.path.sep.join(p)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model 1/2\n",
      "Loading model 2/2\n",
      "Evaluating ensemble...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61        36\n",
      "           1       0.35      0.48      0.41        23\n",
      "           2       0.40      0.90      0.55        29\n",
      "           3       0.41      0.52      0.46        31\n",
      "           4       0.38      0.65      0.48        26\n",
      "           5       0.76      0.73      0.75        30\n",
      "           6       0.79      1.00      0.88        19\n",
      "           7       0.50      0.30      0.37        27\n",
      "           8       0.83      0.36      0.50        28\n",
      "           9       0.33      0.86      0.48        29\n",
      "          10       0.68      0.44      0.54        34\n",
      "          11       0.71      0.30      0.43        33\n",
      "          12       0.68      0.95      0.79        40\n",
      "          13       0.84      0.82      0.83        33\n",
      "          14       0.64      0.48      0.55        33\n",
      "          15       0.69      0.89      0.78        28\n",
      "          16       0.86      0.35      0.50        34\n",
      "          17       1.00      0.97      0.98        33\n",
      "          18       0.53      0.40      0.45        25\n",
      "          19       0.56      0.71      0.63        28\n",
      "          20       0.78      0.85      0.82        34\n",
      "          21       0.69      0.96      0.81        26\n",
      "          22       0.52      0.91      0.67        35\n",
      "          23       0.40      0.66      0.50        32\n",
      "          24       0.63      0.76      0.69        29\n",
      "          25       0.75      0.27      0.40        33\n",
      "          26       0.66      0.78      0.71        32\n",
      "          27       1.00      0.17      0.29        35\n",
      "          28       0.92      0.86      0.89        28\n",
      "          29       0.68      0.48      0.57        27\n",
      "          30       0.56      0.15      0.24        33\n",
      "          31       0.23      0.75      0.35        24\n",
      "          32       0.78      0.26      0.39        27\n",
      "          33       0.58      0.39      0.47        28\n",
      "          34       0.50      0.28      0.36        29\n",
      "          35       0.92      0.68      0.78        34\n",
      "          36       0.65      0.50      0.57        26\n",
      "          37       0.61      0.80      0.69        25\n",
      "          38       0.55      0.77      0.64        22\n",
      "          39       0.85      0.73      0.79        30\n",
      "          40       0.59      0.59      0.59        32\n",
      "          41       0.58      0.52      0.55        29\n",
      "          42       0.60      0.17      0.27        35\n",
      "          43       0.64      0.26      0.37        27\n",
      "          44       0.81      0.56      0.67        39\n",
      "\n",
      "    accuracy                           0.59      1350\n",
      "   macro avg       0.65      0.60      0.58      1350\n",
      "weighted avg       0.65      0.59      0.58      1350\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlLElEQVR4nO3de7QcVZn38e+PEEMgkIQQQhIQFIQIqAlGLjIqNwV1EB11UN8ljAsn884oouOM4MhayLyjgqMweB2j3LwMoOIFHEARAW8IYUIMMAlyEYQQQgjhZiJwcp73j65oe1LV1XVOVXdV5/fJqnX67NpdtbtPn30q+9n7KUUEZmZWnS363QAzs0HnjtbMrGLuaM3MKuaO1sysYu5ozcwq5o7WzKxi7mjNzCq2ZdUnuHvfI1Mn6u71m9tKOf7sbadtUrbiyTWlHDvLi6c9L7V86ZrfVnreLBO2HJ9a/vTQsz1uiY3W1ImTUsvXrn8qtTzrZ771+Amp5euefTq1vG6fkaFnVmisx3j2kXu6Xhwwfofnj/l83cjtaCXNAY4BZgMBPAhcFhHLKm6bmVlxwxv63YJNdBw6kHQycDEg4CZgUfL4IkmndHjeAkk3S7r54kcfKLO9ZmadxXD3W4/kXdGeAOwTEX/2/wtJZwG3A2ekPSkiFgILIXvowMysEsO960C7ldfRDgOzgPtGlM9M9uXKGot936xXpJZ/5sGfdXPYP6p6PDbN/etWl3KctPFlKP6assbZNqex23691qI/w6JjsVmyXtcg/myLig1D/W7CJvI62vcD10i6E7g/KXsusAfw3grbZWY2Oj0cEuhWx442Iq6StCewP61gmIAHgEURUb8RZzOzGgbDcmcdRMQw8KsetMXMbOyadkVrZtY4NQyGqerE31s+Z3ahE6x994tTy6d+ZWkp7RlETQl6lRUIssFVxoKFp+/8Zdd9zoQXvLweCxbMzBrFQwdmZhVrYjDMzKxRanhF6+xdZjZYhoe73zqQtJWkmyT9WtLtkk5Pyj8qaYWkJcn2urwm1e6Kdt9LVqSWXzTtkNTyv3n8F5uU1S0I1HR7TJmVWn7XYw8WOk6VQa9+BQTLOm9TApplrWasVHlXtE8Dh0XEU5LGAz+XdGWy7+yI+FS3B+ome9f+QETEIkl7A0cByyPiitG03MysSrGhnD9O0ZqStfHqYHyyjWqaVl72rtOAzwBflPQJ4HPAJOAUSR8ZzQnNzCpVYvYuSeMkLQEeBq6OiBuTXe+VtFTSeZKm5h0nb4z2LcDBwCuB9wBvjIh/BY4Eju3QuD+mSRwe/n3uizEzK02BMdr2virZFrQfKiI2RMRcYGdgf0n7Al8EdgfmAiuBT+c1qeOCBUm3RMS8kY+T75ckDeio6IKFoi6bmp4F7A1ri2UBK+Kg6XNSy29YvbzQcZoyLmfZvAijXGUsWPjD/3yv6z5nq5e+sevzJf/D/3372Kyk3YAfRMS+nZ6bd0X7jKStk8cvbTv4ZLpMk9gPVXayZlZzwxu63zqQNF3SlOTxROAIYLmkmW3V3gTk3pcrLxj2yoh4Gv6YXGaj8cDxeQc3M+u58vLRzgQulDSO1kXpNyPiB5K+JmkurcDYvcDf5R0oL01i6h3dIuIR4JGCjTYzq15J07siYikwL6X8nUWPVbt5tGZmY1LD7F2N72jf+uSmqXLvnbdXat3dbrmjlHMuXnt3annR4NagBr0cIKqeA6kduKM1M6tWHW/+4o7WzAaLr2jNzCrWwLvgmpk1Sw3TJDa+o00b/M8Kev1qx5ellh/48KIxn9P+ZHMKevXrtfoz2IGHDszMKlbDK9q87F0HSNoueTxR0umSLpd0ZrIM18ysXkpK/F2mvFwH5wHrksfnAJOBM5Oy87Oe5OxdZtY3Nexo84YOtoiIjSG8+RGxX/L450mOxlQRsRBYCNVn7zIz+zMNnHVwm6R3RcT5wK8lzY+ImyXtCfR0ND5rJUyarEBBVtDr6J32Sy2//KHFqeVZK5+yrHs2NWVE7QIaRd5jKK/9Zd0qp4h+rawqa9Vcv35WRfXlfa7hGG1eR/tu4BxJp9JKInODpPuB+5N9Zmb10rRZBxHxOPA3krYFnp/UfyAiVvWicWZmhTXwihaAiHgS+HXFbTEzG7umXdGamTXOBieVGbWswfOiQYE0WUGvE2a9PLX86xlBtaID/HVLddev81YZ9MpS1mv9yvRDU8vfvfra1PKyVpLVLZCapS/t9BWtmVnF3NGamVWsqcEwM7PGqOEVbd4SXDOzZonofutA0laSbpL0a0m3Szo9Kd9e0tWS7ky+Ts1rkiLnZGNVdAlu3QJEadYcOye1fNoly3vckv7yvcEGV79+D4eeWaGxHmP9uf/UdZ8z8YRPZZ5PkoBtIuIpSeOBnwMnAX8FPBoRZ0g6BZgaESd3Ok/u0IGk3YE3AbsAQ8CdwEXJYgYzs3op73bjAWy8ahifbAEcAxySlF8IXAd07Gjz0iS+D/hPYCvgZcBEWh3uDZIOyX6mmVl/xHB0vbVnGky2Be3HkjQuSaD1MHB1RNwIzIiIlQDJ1x3z2pR3Rfu3wNyI2CDpLOCKiDhE0peA7wPz0p6UNHYBgMZNZosttslrh5lZOQoEw9ozDWbs3wDMlTQF+K6kfUfTpG5mHWwJbAAmANsmJ/9dMmaR1bjcNIl1GostOtaYNRabNXn9n59KX+BQ1lhmv97Lqtu/y6TpqeX3P7U6tbzK11tWtqymZN3aevyE1PJGLMqpYHpXRDwm6TrgKGCVpJkRsVLSTFpXux3lzTr4CrBI0kLgBuBzAJKmA4+OqeVmJapTsNT6bDi63zqQND25kkXSROAIYDlwGXB8Uu14Wv+77ygve9c5kn4MvBA4KyKWJ+WrgVfmHdzMrOeGSkv8PRO4UNI4Whel34yIH0i6AfimpBOA3wFvzTtQ7tBBRNwO3D7GBpuZ9UZJU1YjYikpcaiIWAMcXuRYXhlmZoOlhivD+tbR9mNMLWtgPutWM0VlZWzKygJ27vpflnLest7LfgXVzpz2F6nl5w3dm1rej89OWedsylhyVqCz6GekP9m76nebQl/RmtlgcVIZM7NqxZATf5uZVctDB2ZmFfPQQX/1KxBx7oPpQa/1D/4stXzirFdU2ZxM/Xp/3r8qPYjYBJtbBrNGBPNqeEWbl1RmO0mfkPQ1Se8Yse8L1TbNzGwUhoe733okbwnu+YCAS4G3SbpU0sZF0AdW2jIzs9EoaQlumfKGDnaPiDcnj78n6SPATyS9odOTnL3LzPqmgbcbnyBpi4jW6HJEfEzSA8BPgfTBKbrL3mVmVoVo4Mqwy4HDgB9vLIiICyWtAj5bZcM2B1lBr8dO2j+1fMo5N1XZnMq9eNrzUsuXrvltj1tSnqYEveqUlrRyNQyG5WXv+lBG+VWSPl5Nk8zMxqCGHe1Y7oJ7emmtMDMrSwx3v/VIxytaSUuzdgEzym+OmdkY1fCKNm+MdgZwJLB2RLmAclJPmZmVKIaaFwz7ATApIpaM3JHcP6dn9pgyK7V8zdNPbFLWlABFlhmfvyW1/KJph6SWv33NddU1hvLuc5UV9CojUDN722mp5SueXNP1MaB/K72qPu9ABr2yNG3WQUSc0GHfO7L2mZn1TQOHDszMmqWGHe1YZh2YmdVORHS9dSJpF0nXSlom6XZJJyXlH5W0QtKSZHtdXpt8RWtmg6W8YNgQ8MGIWCxpW+B/JF2d7Ds7Ij7V7YHypncdFRFXJY8nA2cBLwNuAz4QEatG1fwOsgIjdz32YNmnqq2swEVW0GvNsXNSy2ddeneh4xdtT1nKOH7RoFeWfgVSi553s1rpVVCUNHQQESuBlcnjJyUtA2aP5lh5Qwftq78+nZz0aGAR8KXRnNDMrFIVZO+StButW4/fmBS9V9JSSedJmpr3/CJjtPMj4tSIuC8izgZ2K/BcM7PeGO5+k7RA0s1t24KRh5M0iVaq2PdHxBPAF4Hdgbm0Lj4/ndekvDHaHSX9I60FCttJUvxpBDmzk3aaRDPrlyJDB+2ZBtNIGk+rk/1GRHwnec6qtv1fprXeoKO8jvbLwLbJ4wuBHYDVknYClnTT+Kw0iVljTBdMPji1PGt80mNVMO2S5anlp8x6VWr5GQ9eX2VzNiv9+vwVPX5Z7WzErXtKGqOVJOBcYFlEnNVWPjMZvwV4E62YVUd5CxZSE8dExEOSanujp82pkzWzPxdDpc2jPRh4J3CrpCVJ2b8Ab5c0FwjgXuDv8g40luldp9O61Y2ZWX2UNLsrIn5Oa9h0pCuKHsvZu8xsoJQ1vatMzt5lZoOlfjll+pe9q+ikfCsuK+j15CUnppZve6zvTlRUU+IBZbWzVkGvDD3M5901Z+8ys4ESQ/1uwaac68DMBkvTrmjNzJqmcUMHZmZN4462TdGVKmWsbClrdUzdjlNUVtDrhFkvTy0/98FiE0y8Wq9/ylq5ddD09Ixwi9eWkxGuSnXsaDsmlZE0P0l8+/UkCe7Vkh6XtEjSvF410sysa6Hutx7Ju6L9AnAaMIXWvNkPRMSrJR2e7Duo2uaZmRUzPNS7DrRbeWkSx0fElRFxERAR8W1aD64Btsp6UnvqseHh35fYXDOzzmK4+61X8q5o/yDpNcBkICS9MSK+J+lVwIasJ3WTvcvMrArRwyGBbuV1tP8X+CStmWlHAn8v6QJgBfC3Yzlx0cHzrcdPGPNxyhqwLytgV7Q9s7edllpe1m1csoJeS3ZOH46f+8AtqeVlvc9F3k8H4FrKWrl1w+r01JtN0LhgWET8OiKOjIjXRsTyiDgpIqZExD7AXj1qo5lZ12JYXW+9MpbbjafmqjUz66eI7rdecZpEMxsow0NjuX6shtMkmtlA6eWVarf6liaxqKxB/rQgSNXBmKzAXNUp5MoKehWVFfR64ozXpZZPP/Xq1PKiP5d+BDqt+Xo59totp0k0s4HSxOldZmaN0rjpXWZmTbNheIuut06S/C7XSlom6XZJJyXl2yd5X+5Mvk7Na9OoO1pJV472uWZmVSlxHu0Q8MGIeCFwIPAeSXsDpwDXRMQLgGuS7zvKm961X9YuYG7ewXuhyiBIWSu6BtV2p6TfdXnNsekp9qZd0tzVRlm8Iq1+ypp1EBErgZXJ4yclLQNmA8cAhyTVLgSuA07udKy8MdpFwPWk39t8SrcNNjPrlSpmHUjaDZgH3AjMSDphImKlpB3znp/X0S4D/i4i7kw58f0dGrUAWACgcZPZYott8tphZlaK4QKzDtr7qsTCJClWe51JwKXA+yPiCal4R57X0X6U7HHc9HtW4+xdZtY/RaZ3tfdVaSSNp9XJfiMivpMUr5I0M7manQk8nHeevHm035Y0J0n0fWNEtM/I/0Puq7BR6cdtfsqUNRb75CXpf5uzbq3TBE0Zi63bZ6RKG0oaOlDr0vVcYFlEnNW26zLgeOCM5Ov3846Vdyub9yUHORG4TdIxbbs/XrDdZmaVi1DXW46DgXcCh0lakmyvo9XBvlrSncCrk+87yhs6+FvgpRHxVDIY/G1Ju0XEOaQHyMzM+qrEWQc/J7ufO7zIsfI62nEbhwsi4l5Jh9DqbHft0AAzs74pEgzrlbwFCw9Jmrvxm6TT/UtgB+BFFbbLzGxUShw6KE3eFe1xtFZH/FFEDAHHSfpSZa2qyOYUEBiNqt+frKDXHXvum1p+4P33ppZXnSVtEO0wcbvU8qIZ4aZOnJRaXqefSR2vaPNmHTzQYd8vym+OmdnYbGhaR2tm1jROk2hmVrEaZkksnr2rm3W9Zmb9EqjrrVfysndtP7IIuEnSPEAR8WhlLatAv4JeRYNMVd7ypRfHKeqta36fWn7LnNmp5bvdckeVzRlIj6x/opTj1CnolWW4hov+84YOHgHuG1E2G1gMBPD8KhplZjZaG2p4P4O8jvZDwBHAP0fErQCSfhsRz6u8ZWZmo1DHMdq86V2fknQxcHaSFvE0WleyHTlNopn1Sy/HXruVe40dEQ9ExFuBa4Grga27eM7CiJgfEfPdyZpZLw0X2Hold3qXpDm0xmWvBX4M7J6UHxURV432xP1YpdWvlWFZx3/xtPQRmDseT18n0vQVbLO3nZZavnTNb1PLd8tYtPS2mQdsUnbxyhtH3a6xOHqn9Ls9Xf7Q4h63pLOqPztFV4xlfRbKUMehg0JpEoHXRMRtyW6nSTSz2mnc9C6cJtHMGmZoFLeaqZrTJJrZQKnhNFqnSTSzwVLHYJiiQzpySTsDQxHxUMq+g7vJ4NWPmzNmDcyve/bp1PKmB5mq1oT0kmuOnZNannX/sqLKSg/YhPeyn4aeWTHm/yl/e+b/6brPecvKb/Tkf+ZOk2hmA6WOQwfO3mVmA6Vx07vMzJpmSOp6yyPpPEkPS7qtreyjklaMuDNuR3nzaBdLOlXS7l29QjOzPosCWxcuAI5KKT87IuYm2xV5B8kbOpgKTAGulfQQcBFwSUQ82F0bs+0xZVZq+foN6QGrIvc2Khr0ymrLXY8Ve5lND3QUDSJWfd4igaasoNdB09ODZDesLhYkKys9YNHPQtHPVNZqw/vXrU4tLytAnNXOLFX+TgyXGN6KiJ8mawjGJG/oYG1E/FNEPBf4IPACYLGka5PEMWZmtVJkepekBZJubtu67dfeK2lpMrQwNa9y12O0EfGziPgHWnkPzgQOyqrb3vjh4fSkzmZmVSgydNCeACvZFnZxii/SyvkyF1gJfDrvCXlDB7/Z5EVEbACuSrZUSWMXQn/m0ZrZ5muo4pmxEbFq42NJXwZ+kPecvHm0b2vL3nXjxuW4yQnGlL2ryvHPouM/RduSpSljsVmyxiGzxlDLer1V3h4layz24dfukVq+45V3FTp+1ePyRY+TlQmtanX67Fc9vUvSzIhYmXz7JloJtzrKm3VwIm3ZuyQd07bb2bvMrHZC3W95JF0E3ADsJekBSScAn5R0q6SlwKHAB/KOkzd0sABn7zKzBinzijYi3p5SfG7R4zh7l5kNlCauDHP2LjNrlJIXLJQi74r2OGCovSAihoDjJH2pslal2GHidqnlRRYyNF1ZCyuKKmvBQpWBo6xbo2R9PrKCXv8289DU8lNXXptaXqcgUCdlvfdNWJRT9ayD0XD2LjMbKHUcOnD2LjMbKHWcuO+O1swGSpm5DsrijtbMBkrjhg4kTQY+DLwRmJ4UP0xrEcMZEfFY3gmyVhUdOWWf1PLvrl6cd8i+61dAoOqgV1m3a8lS5ftTVlD0gvV3pJZnZcXKWolVNJtVlqpXmBX9LBc9TtH2lKGOQwd507u+CawFDomIaRExjdZKiLXAt6punJlZUUNE11uv5HW0u0XEme03Z4yIhyLiTOC51TbNzKy4Os6jzeto75P0IUkzNhZImiHpZOD+rCe1p0n8wzOPldRUM7N8dbzdeF5HeywwDbhe0lpJjwLXAdsDf531pPYcj1s9Z0pZbTUzyzWs7rdeyVuwsFbSpcC3I2KRpH1o3T9nWUQ82s0JsgIpF6+/MbU8a1A9K9iRVn/r8RMKtaWosgby67bKpsp0hVC/15umaMDxJ9u/PLX8sEd/WUZzKtevdI5VGq5hOCxv1sFpwGuBLSVdDewPXA+cImleRHysB200M+vahn43IEXePNq30LpdwwTgIWDniHhC0r8DNwLuaM2sVhp3RQsMJbeuWSfp7oh4AiAi1kuq47xgM9vM1a+bze9on5G0dUSsA166sTBZyOCO1sxqp44dU15H+8qIeBogItrbPx44vooGlTGoXlZavyz9Cupknbfq4F9RWSvMpk1IT3VZxv3j+hWM+ci49Jjw4TNenFp+zaqlVTbHaODQwcZONqX8EeCRSlpkZjYG9etm8+fRmpk1ygai6y2PpPMkPSzptray7SVdLenO5OvUvOO4ozWzgVLyyrALaK0daHcKcE1EvAC4Jvm+o7zbje8k6YuSPi9pmqSPJrfZ/aakmd2108ysd4aJrrc8EfFTYORA/DHAhcnjC2llN+woLxh2AfDfwDbAtcA3gNcnJ/rP5Gupsu6Ldf9Tq1PL+xEEqTrlXNHzVv0eFE0RmBWEyyov430res+wsgKai9feXeg475v1itTyzzz4s0LntWw9GKOdERErASJipaQd856QN3QwIyI+GxFnAFOSTF6/i4jPAruW0GAzs1IVuaJtT4CVbAuqaFPeFW17R/zVDvv+TNLYBQAaN5kttthmdK0zMyuomyDXRhGxEFhY8BSrJM1MrmZn0roZQkd5V7TflzQpadCpGwsl7QH8JutJ7dm73MmaWS/1IE3iZfxpHcHxtO4405EiOvf+kvYHIsnetTetCNzyiLiimxZts/VuhYZMio6RpU0M//maZaUcO2scb5dJ01PLy5h4D+WNAVv1yrr9z9E77ZdafvlD6bd2qvq2Q/0y9MyKMScvfNdub+66zzn/3ks7nk/SRcAhwA7AKuA04Hu07j7zXOB3wFvzshkWzd51AK18tM7eZWa1VOYS3Ih4e8auw4scx9m7zGygDOf8L70fnL3LzAZK/bpZZ+8yswGzoYZdU+XZu6rOLFVlNqSsINMLt9optfwuigXDylqwYP1T1uc4K+i14uA9Ustn/+Ku1HIHTOt5BejsXWY2UBqXJtHMrGnCHa2ZWbUaN3SQRtK0iEjP1GFm1md5i7D6IW/BwhnApyLiEUnzaa2GGJY0HjguIq7PO0HRjE1ZsoJqW2+5aXlWxqayZAUuNjeDujqpiLLeg6zfh+ffeF9q+b/NPDS1/NSV1xY67yAaquHQQV6ug9cngS+AfweOjYg9gFcDn660ZWZmoxAF/vVK3tDBeElbRsQQMDEiFgFExG8kpV9impn1URNnHXweuCIZQrhK0n8A36G1zndJ1pOcJtHM+qVxY7QR8VlJtwJ/D+yZ1N+TVvaaf+vwvD/meNzyObPr96rNbGA1ddbBOloBsUWS9qGVJvGBiKhkqUnR27WspfeBl6K3TcnS9FU8m1PQK0tZ70HRn3lW0GvJzvNSy+c+cEvhNjVV45bgpqRJ3B+4HqdJNLOaatzQAU6TaGYN08RgmNMkmlmjNHEJrtMkmlmjNDHx95jTJA7ifbHKWnlW1nvQhPcMmtPOJssKel029RWp5W9Y+7Mqm9MX9etmnSbRzAbMUA3/s+3sXWY2UMqcdSDpXuBJYAOtmNX80RzHHa2ZDZQKZh0c2pbzZVQ6JpWRNEnSv0q6XdLjklZL+pWkvxnLSc3MqtLEpDLfAL4LHAn8NbANcDFwqqQ9I+Jf8k5QNNCRlQ6xSCCo6uBK1ekBB/VeYk1pZ5X6FRDMCnrdO2+v1PJ5y1ekljdhNWCRoYP2vCyJhUkKgT8eDviRpAC+NGJf1/I62t0i4oLk8VmSFkXE/5P0LuB/gdyO1sysl4oMHbTnZclwcEQ8KGlH4GpJyyPip0XblJeP9veS/gJA0tHAo0njhgFlPUnSAkk3S7p5ePj3RdtkZjZqG2K46y1PRDyYfH2Y1v/u9x9Nm/I62r+ndSX7GHAycCKApOm0UihmNW5hRMyPiPlOkWhmvVTWGK2kbSRtu/Ex8BrgttG0KW8e7a8lnQgMJ9m79pb0j8DyiPhMNycoOp5Z9NY3HvcbXEV+5k35fJTVnqzXmxXjyLLXrfekll+//dzU8gPXLyp0/H4ocWXYDOC7kqDVV/5XRFw1mgMVzd51AHAdzt5lZjVV1myCiLgHeEkZx3L2LjMbKE3MdeDsXWbWKN0EuXrN2bvMbKDUMU2iOk3ulTQhLbGMpB2AmRFxa94Jit4zbI8ps1LL129IzW9TWiatJmtKICjrFkBZ/LOtn69MPzS1/N2r02+tU9TQMysyp412a/cd9uu6z7n7kcVjPl83nL3LzAZKHa9onVTGzAZKNHCM1sysUZp4zzAzs0ap46yDvGDYdsCHgZ2BKyPiv9r2fSEi/iHvBHN2fFnqCe567MHU+lmBnSxpK2GqzjBUVvaurOBQU4JA/brlTj8ytmU5YdbLU8u//nD6Cqq6BSjLctD0OanlN6xenlqe9Tu0+vE7xhycmj11n64vaVesvb0nwbC8XAfn00oecynwNkmXStrYsx1YacvMzEZhOKLrrVfyhg52j4g3J4+/J+kjwE8kvaHidpmZjUoTZx1MkLTFxjvgRsTHJD0A/BRIv/bnz5Ppzpi0K1MmTi+rvWZmHZV5z7Cy5A0dXA4c1l4QERcCHwSeyXpSe5pEd7Jm1kvDRNdbr3QMhqU+QfpqRBzXbf2iK8OKKiMwUjRIc/RO+6WW/+iR9IVyTQmAFA3yZdVf92z6Kr6mvA9pmrL6rqii6RaLBnwPn/Hi1PJrVi1NLS9jZdj2276g6z7n0Sfv7P/KMEmXjSwCDpU0BSAiPFZrZrVSx6GDvDHaXYDbga/QukmZgPnApytul5nZqNRxwULeGO1Lgf8BPgI8HhHXAesj4vqIuL7qxpmZFRURXW+9kpdUZhg4W9K3kq+r8p5jZtZPdUz8XSgYJun1tG6/2/VtxqsOhln9AjVZqS5fuNVOqeWXP7S4yuZUqqxVglWrclXeaI5z77y9Ust3vvEnYw5OTZy4a9d9zvr199ViZdifiYj/LtLJmpn1WplDB5KOknSHpLsknTLaNhXqaM3M6q7E242PAz5P6wa1ewNvl7T3aNrkjtbMBkqJV7T7A3dFxD0R8QxwMXDMaNrkwJaZDZQSZxPMBu5v+/4B4IBRHalI7z/WDVjg+v2pX6e2uL5/tmOpX+ZGKyfLzW3bgrZ9bwW+0vb9O4HPjuo8PX5RN7t+f+rXqS2u75/tWOr3agMOAn7Y9v2HgQ+P5lgeozUzS7cIeIGk50l6DvA2YGRagq54jNbMLEVEDEl6L/BDYBxwXkTcPppj9bqjXej6fatfp7a4frn169SWXtTvmYi4ArhirMcpnCbRzMyK8RitmVnF3NGamVXMHa2ZWcUq7WglzZF0sqTPSDonefzCnPqHS5o0ovyoLs711Zz9B0jaLnk8UdLpki6XdKakySPqPkfScZKOSL5/h6TPSXqPpPT0RVYpSTsWrD+tqrZUbXN6rVD89TZRZR2tpJNprQ0WcBOtOWkCLkrLgiPpfcD3gROB2yS1ryn++Ii6l43YLgf+auP3GU06D1iXPD4HmAycmZSdP6Lu+cDrgZMkfY3WCpEbgZfRuttELfTrF1LSZElnSFouaU2yLUvKpqTU307SJyR9TdI7Ruz7Qkr97Uds04CbJE2VtH1K/TMk7ZA8ni/pHuBGSfdJelVK/fmSrpX0dUm7SLpa0uOSFkmat7m+1jq+3oFR4aqK3wDjU8qfA9yZUn4rMCl5vBut5XAnJd/fMqLuYuDrwCHAq5KvK5PHr8poz7L254/Yt2TE90uTr1sCq4BxyffauC/l+JOBM4DlwJpkW5aUTUmpvx3wCeBrwDtG7PtCSv3tR2zTgHuBqcD2KfXPAHZIHs8H7gHuAu4b+R4l+69N3tNdgKuBx2n9cZyXcuwfAicDO7WV7ZSUXZ1S/9KkPW+kNeH7UmBC2s8iKRsGfjtiezb5ek/aZ6ft8bXAy5LHe5Ky6ojWH/7XAm+ntZb9LUn54cANm+trrePrHZStugO3OpxdU8p3Be5IKf/fEd9PAq4CzmLTjnAL4AO0OoS5SVnHHxLwLeBdyePzgfltH9BFI+reRusPwlTgSZKODNiKtg67zh/QIr+Qo/hl3OTn12lfys/vI8AvaP2xSHut/5T87F/UVvbbnM/alsnjX2W9D21lt7Q9/l3Wvs3ttdbx9Q7KVt2B4ShaV1BX0pqQvDB5g+8Cjkqp/xOSTrOtbEvgq8CGjHPsTKsD/dzID1FK3cnABcDdtIYBnqV1lXc98JIRdT+Q7LsPeB9wDfBlWlfdp3X7IeznB7TIL+Qofhl/BHwImNFWNoPWH5Ufp9RfBmwxoux4Wjf+vC/nZ3sWsC0d/pDSGm76EXAY8FHgP4BXAqcDX0upfwPwGlpDQvcBb0zKX8Wmf4Q2m9dax9c7KFu1B29deR4IvBl4S/J4XIc3f6eMfQfnnOf1wMe7bNO2wEto3XhyRod6s4BZyeMpSfv371C/Vh/QIr+Qo/hlnEprfHs5sBZ4NHk9Z5I+jPFJ4IiU8qNIGUYaUedo4FfAQzn1DgEuAW6h9QfxClqZmdKGr15C638gVwJzaI3ZP5a89y/fDF7r2uS1bvJ7lfJ61yav95MVvN43dPN6B2HrewMGZRvxAX10xC/k1JT6/fyF3HJEva47nrbnzAGOIBlXb29/h/qHp9R/bV59YCKw7yiPn1X/hd3Wp5UAeuPQyz7AB4HXdXjf2+vvDfxjgfovAk4tUL+b9hxQpH7K8ze5Us6p/9UCdScC3ypy/CZuXoLbA5LeFRHnl1lf0kRg94i4rYrjd6qbzBB5D60/JHNpBS2/n+xbHBH7jah/IvDeAvWLHn809f+B1h/FjvUlnUZr/HpLWjGB/WkNNx1BK4Xex0Yce2T9A4DrCtQvevyy66fN2jmM1tAeEfGGnPoCDi1Qv+PxB0a/e/rNYSNn/LjO9dPqUmCGSNPrJ3XHAVsDTwDbJeUTSZmBMgD1C83oofW/pSL1C88YGoTNaRJLImlp1i5aY7W1rV/02LTG2Z8CiIh7JR0CfFvSrslzBqn+UERsANZJujsinkiet17ScMqxm15/PnASreDsP0fEEknrI+L6lLrQinUUqV/0+APBHW15ZgBH0goetBPwy5rXL3rshyTNjYglABHxlKS/pLUo5EUDVv8ZSVtHxDpanQrQmthPa8rdSI2uHxHDwNmSvpV8XUWHfqLq+gOj35fUg7IB5wJ/kbHvv+pcfxTHLjRDpMn1SeY2p9TbgbapdoNSP6Ve1zN6elG/qZuDYWZmFXP2LjOzirmjNTOrmDtaM7OKuaM1M6uYO1ozs4r9f/37uP5MBomAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "from seaborn import heatmap\n",
    "# construct the path used to collect the models then initialize the\n",
    "# models list\n",
    "modelPaths = os.path.sep.join(['models2', '*.model'])\n",
    "modelPaths = list(glob.glob(modelPaths))\n",
    "models = []\n",
    "\n",
    "# loop over the model paths, loading the model, and adding it to\n",
    "# the list of models\n",
    "for (i, modelPath) in enumerate(modelPaths):\n",
    "    print('Loading model {}/{}'.format(i + 1, len(modelPaths)))\n",
    "    models.append(load_model(modelPath))\n",
    "\n",
    "# initialize the list of predictions\n",
    "print('Evaluating ensemble...')\n",
    "predictions = []\n",
    "\n",
    "\n",
    "testX = np.concatenate([x for x, y in val_ds], axis=0)\n",
    "testY = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "\n",
    "# loop over the models\n",
    "for model in models:\n",
    "    # use the current model to make predictions on the testing data,\n",
    "    # then store these predictions in the aggregate predictions list\n",
    "    predictions.append(model.predict(testX, batch_size=64))\n",
    "\n",
    "# average the probabilities across all model predictions\n",
    "predictions = np.average(predictions, axis=0)\n",
    "\n",
    "#show a classification report\n",
    "print(classification_report(testY,\n",
    "                            predictions.argmax(axis=1)))\n",
    "\n",
    "heatmap(confusion_matrix(testY, predictions.argmax(axis=1)))\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
